## Troubleshooting performance of tableau live connections to SQL Server - part 1. BASICS.

ðŸ‘‹ Hello everyone, wish you enjoy reading these findings I've gathered over a couple of years working with this type of scenario

#### Background

ðŸ’› Tableau and SQL Server are great tools but they may be troublesome to set working together.

There are use cases when you'd want to use *live* connection as opposed to *extracts*. These include, but not limited to cases when you want to use:
* integrated authentication in the DB,
* minimize storage footprint at the tableau server, 
* or your application requires that live data is retrieved from the DB
and many others.

The problem is, this might not perform well out-of-the box.

#### Problem description

ðŸ’” An often occuring problem is performance of such connections. You may have just a handful (<< 1mln) of rows in the source tables, but the dashboards would take minutes to load.
This is especially true when you are getting data from a view (or a chain of views), not from a table.

> A note here: such design (chaining views) has been critisized a lot for poor performance - I even saw it taggedÂ bad practice - but I'm a big supporter of that because it saves a lot of coding and code maintenance. I will probably blog about it at some point; for now - don't rush to materialize everything to tables.

#### Why does it happen?

> note: if you want to skip to a list of concrete troubleshooting steps, please read part 2.

Let's review what is happenning every time when a user presses a refresh button. I may be drawing a simplified and not 100% strict description here, but I believe it is usable.

Every time user clicks refresh:
1. Tableau engine would create a set of SQL queries it deems necessary to (optimally) retrieve data from the DB.
   Tableau sort of assumes that all objects that you gave it as data sources *are tables*. And generates queries with no respect for the complex logic you might have under the hood of these views.
2. These queries are then executed at the SQL server in some order[^1] [^2].,
3. The DB, having received a query, determines the (optimal) execution plan and sends the results back to Tableau
   Theres's a common misconception that SQL Server performs all calculations inside the view - the way you would see in the SSMS, stores the result somewhere in cache and passes the rows to Tableau - to which Tableau performs in-memory aggregations, filtering and stuff. This is not true. What happens is that the SQL Server gets a query from Tableau (which contains casts, groupings, where-clauses etc) and tries to optimize *this particular query* with all its quirks - all the way down to base tables. If the query contains a lot of nuances, chances are, SQL server will take a suboptimal path.
4. Tableau renders them in your viz.

The problems mainly happen because the SQL code generated by Tableau on step #1 is *tough* for the DB engine to optimize on step #3. And SQL Server takes a suboptimal execution path leading to long waits. In other words, your database needs *the right design* to perform well in such scenarios.

#### I want to see the problem with my own eyes, how do I do this?

ðŸ”Ž Well, there are (at least) 2 good ways to do this:

1. Using the sp_whoisactive stored procedure,
   -  Download the sp_whoisactive stored proc. http://whoisactive.com/downloads/. When executed it shows the list of running processes with the SQL query.
      > note â€“ one needs to have VIEW SERVER STATE permission
    - Call refresh on the problematic tableau dashboard (server/laptop). Tableau would assemble SQL queries and fire them back to the database
    - Immediately after you press refresh, exec sp_whoisactive on the SQL server. Most likely you will intercept a couple of these queries
    - Press on the SQL_text and behold the generated code. Normally it inclines towards spaghetti-code generation, but there are ways to streamline it and make more deterministic
    - You take this SQL code and against the DB engine in an SSMS window. You will see the same performance that tableau gets. You can also use Live Query Plan option - but I won't go into query optimization now.

2. Using tableau server performance recording feature,
   - What it does: Tableau logs all operations, incl. execution times and query texts, it needs to display you the result. When ready, you can see which queries or operations took the longest.
   - Normally you would expect to see the DB as the bottleneck - because the layout stuff is normally fast.
   - In tableau desktop - click create performance recording. If your book is deployed on the server, add :record_performance=yes&:refresh=yes&:iid=1 to the bottom of your URL, so that it looks like this (taken from tableau help)
     > http://10.32.139.22/#/views/Coffee_Sales2013/USSalesMarginsByAreaCode?:record_performance=yes&:refresh=yes&:iid=1
   - Make sure to add *&:refresh=yes* so that the server actually refreshes the cache.
   - When finished, you'll see a timer icon at the toolbar that says performance. Open it - you'll see the query durations and texts - if you hover over specific bars.
     > Please read tableau help page for more details.  https://help.tableau.com/current/pro/desktop/en-us/perf_record_create_desktop.htm

Now that you know how to see the exact queries that are executed on the server, you can skip to part 2.

[^1]: If you're using tableau desktop, then the queries will use your AD account to authenticate and query SQL Server. If you are refreshing data from the Tableau server, it uses the *ServiceAccount* the server is running.
[^2]: The order is sometimes sequential and sometimes parallel. For instance, it tends to first retrieve data for filters on the dashboard - and only after that it retrieves data for your visuals, that is sequential. However it might decide to parallelize and execute a number of SQL queries in parallel - this seems to happen when you have multiple filters on your dashboard.
